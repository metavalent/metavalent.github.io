---
title: 'AI-Dissociated Human Behavior'
author: metavalent
layout: post
published: true
comments: true
categories: metavalent
tags: metavalent
created: 2024-03-01T11:11:11-07:00
modified: 2024-03-01T11:11:11-07:00
---

### Is AI Splitting Us From True Ourselves?

Extending and augmenting human understanding and intelligence, Being Cyborg, doesn't mean the end of Being Human. In fact, it might be the real beginning.

<div style="max-width:854px"><div style="position:relative;height:0;padding-bottom:56.25%"><iframe src="https://embed.ted.com/talks/lang/en/esther_perel_the_secret_to_desire_in_a_long_term_relationship"loading="lazy" width="854" height="480" style="position:absolute;left:0;top:0;width:100%;height:100%" frameborder="0" scrolling="no" allowfullscreen></iframe></div></div>

Watch [The secret to desire in a long-term relationship](https://www.ted.com/talks/esther_perel_the_secret_to_desire_in_a_long_term_relationship) if the embed does not behave nicely.

<div style="max-width:854px"><div style="position:relative;height:0;padding-bottom:56.25%"><iframe src="https://embed.ted.com/talks/lang/en/esther_perel_rethinking_infidelity_a_talk_for_anyone_who_has_ever_loved"loading="lazy" width="854" height="480" style="position:absolute;left:0;top:0;width:100%;height:100%" frameborder="0" scrolling="no" allowfullscreen></iframe></div></div>

Watch [Rethinking infidelity ... a talk for anyone who has ever loved](https://www.ted.com/talks/esther_perel_rethinking_infidelity_a_talk_for_anyone_who_has_ever_loved) if the embed does not behave nicely.

#### Owning the Wanting

Esther Perel clarifies the meaning of, "If you wanted to, you would." She calls it *owning the wanting*. We can spin those words to take offense without changing their veracity, as Esther explains like no other.

Choosing the direction and desires for our life is a matter of the most profound personal responsibility, especially in this AI-infused [Post-Automation Era](https://postautomationera.com/). Not to be understated, this choosing occurs within the context of our environment. It's another both-and situation, as usual. Environments powerfully shape, constrain, and influence our options and behaviors. At the same time, blame for our choices is the projection of shame. For acutely conscientious humans, the responsibility to *not accept blame* when convincingly, yet unjustifiably piled upon us is at least equally challenging as owning our own accountability in the first place. The acutely conscientious can tend to accept others' experience of feeling like baggage as our own baggage, somehow feeling responsible for their lack of direction and meaning in life.

As much as someone screams at us, "you *made me* do this," we are not responsible for the internal experience, much less outward behavior of others, however much we may have allowed ourselves to be convinced otherwise. We can, however, be manipulated into reacting to such statements in ways that are then excoriated as causal to prior dissonance and discord. That's called [reactive abuse](https://duckduckgo.com/?q=reactive+abuse).

Mouthing the words "I love you," while seldom or never demonstrating affection, saying "I miss you," and never calling, are examples of what may be signs and symptoms of [psychological splitting](https://duckduckgo.com/?q=psychological+splitting) or [dismissive, avoidant, and dissociated](https://duckduckgo.com/?q=dismissive%2C+avoidant%2C+and+dissociated) mental and emotional states.<sup>1</sup>

Is everyday AI helping humans, here? If not, why not?

Today, AI seems mostly ambivalent in its role of enhancing and augmenting human intelligence and influencing human intentions. At the same time, one practical definition of *the alignment problem* seems to be: "to what extent *should* ambivalent AI be the rule?"

AI's are already being modified *by humans* to lean in one direction or another on moral, ethical, and socially charged topics. Training data are curated and crafted toward slightly altering human beliefs and behaviors in ways that are generally beyond our everyday perception; in ways and for purposes that benefit platform engagement rather than human wellness, unless we train ourselves to become acutely aware of what's happening. Why did *that* particular unstable person begin popping up so frequently in our timeline? Why did *that* particular activity or suggestion become increasingly common in our infinite scrolling? What unaddressed shadow-work within inside ourselves may have invited those inputs? Once invited in, what were the undeniable empirical outcomes of those inputs, IRL?

Is AI-Powered Dissociation the fault of AI, or our own personal responsibility? Are we projecting our shame as blame upon AI, because AI is the handiest modern scapegoat of the moment? After all, we are the ones who choose what we put into our brains. We are the ones who choose what we read and how much, what we focus upon, which of our impulses to indulge and which of our principles to abandon. Or vice versa.

#### The Vice-Versa is Possible and Accessible, Right Here, Right Now

The moment we realize we've driven way too far down the wrong road, we can turn around. In this very moment.

Even though we have been algorithmically conditioned and encouraged to forever chase *what we want* &ndash; you do you! &ndash; as the solution to all of our problems. Even though we are constantly bombarded by default algorithmic social media signals that convey the messages that *settling* for contentment and *wanting what we have* are somehow abdications of the right of *getting what we want*. Even though stability is disparaged as a boring life, of not living a *strong and independent* life. As Esther describes, in actuality, fleeting moments of *boredom* are integral to the stable foundation of *settledness* that we at least say we crave.

How can we intellectually know that all the outward chasing in the world can never satisfy, yet keep chasing anyway, effectively turning settledness, security, and stability into *boredom* and then self-sabotaging again and again? How can AI help us integrate rather than dissociate?

Why can't AI training data be curated and coached to lean in the direction of helping humans to self-identify our vulnerabilities and gradually work on addressing them, rather than exploiting human emotional and psychological weaknesses in the name of "just doing my J.O.B.?" If AI can be taught and trained to do that, and [it can](https://metavalent.com/metavalent/2024/03/01/08-08-08-Individuated-Collective-Intelligence.html), doesn't that seem like something worthwhile and useful to do for meaning, purpose, and dignity in the [Post-Automation Era](https://postautomationera.com/)?

<small>[1]</small> Especially when amplified by AI, we must become increasingly vigilant to not become pseudo-expert in spotting contradictions in others, while completely blind to deficits in ourselves, or rationalizing and defending our shortcomings as *just the way I am, take it or leave it*, while condemning identical behavior in others.

---
> Have you discovered or learned something interesting or valuable? Something that piqued your imagination, sparked creative insight, deepened research, enlivened discovery, or shed new light upon other academic, philosophical, or spiritual interest? Make it real with ETH 0x1eb2d6E3f26fBBF31B485bbe3e316D6dAd806632, Cashtag [$metavalent](https://cash.app/$metavalent), [Patreon](https://patreon.com/metavalent), or justbepono$paystring.crypto.com Mahalo means Respect and Gratitude without measure.üôèüèº
